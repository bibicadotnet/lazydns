# Downloader Plugin + Cron Scheduling
#
# This configuration demonstrates a lightweight, plugin-based approach
# for automatically downloading and updating DNS rule files.
#
# Architecture:
#   1. CronPlugin triggers on schedule (every 6 hours: 00:00, 06:00, 12:00, 18:00 local time)
#   2. CronPlugin invokes the Downloader plugin via invoke_plugin action
#   3. Downloader downloads files and updates them atomically
#   4. DomainSet/IPSet/Hosts automatically detect changes and reload
#
# Logging:
#   - CronPlugin outputs DEBUG logs for job scheduling and execution
#   - DownloaderPlugin outputs detailed logs for each file download
#   - Set log level to debug or trace to see detailed operation logs
#

# ============================================================================
# ADMIN API CONFIGURATION
# ============================================================================

admin:
  # Enable admin API for runtime management
  # Admin API provides endpoints for:
  #   - /api/cache/control - Cache management (clear, stats)
  #   - /api/config/reload - Config hot-reload
  #   - /api/server/status - Server status
  enabled: true
  # Listen address (default: 127.0.0.1:8080)
  # Warning: Do NOT expose to untrusted networks!
  # Use a reverse proxy with authentication in production
  addr: "127.0.0.1:8080"

metrics:
  # Enable monitoring server for Prometheus metrics and health checks
  enabled: true
  # Listen address (default: 127.0.0.1:9090)
  addr: "127.0.0.1:9090"

# ============================================================================
# PLUGINS CONFIGURATION
# ============================================================================

plugins:
  # ========================================================================
  # Data Providers - Load DNS rule files
  # ========================================================================

  # Load domain blocklists (Ad, etc.)
  - tag: domain_reject_list
    type: domain_set
    args:
      files:
        - "reject-list.txt"
      auto_reload: true # Automatically reload when file changes

  # Load domain proxy list
  - tag: domain_proxy_list
    type: domain_set
    args:
      files:
        - "proxy-list.txt"
        - "proxy-ext-list.txt"
      auto_reload: true

  # Load domain direct list
  - tag: domain_direct_list
    type: domain_set
    args:
      files:
        - "direct-list.txt"
        - "apple-cn.txt"
        - "my-domain-list.txt"
      auto_reload: true

  # Load IP direct list
  - tag: ip_direct_list
    type: ip_set
    args:
      files:
        - "china-ip-list.txt"
        - "white-ip-list.txt"
      auto_reload: true

  # Load hosts files
  - tag: hosts_files
    type: hosts
    args:
      files:
        - "hosts.txt"
        - "hosts-github.txt"
      auto_reload: true

  # ========================================================================
  # Cron Scheduler - Triggers downloader on schedule
  # ========================================================================

  - tag: auto_update_scheduler
    type: cron
    args:
      jobs:
        - name: auto_update
          # Cron expression: minute hour day month weekday
          # Note: cronexpr uses the standard crontab order (minute hour day month weekday)
          # Examples:
          #   "5 2 * * *" = every day at 02:05 (local time)
          #   "0 */6 * * *" = every 6 hours at minute 0 (00:00, 06:00, 12:00, 18:00 local time)
          #   "0 * * * *" = every hour at minute 0
          # You may optionally append a TZ name as the last token: e.g. "0 */6 * * * UTC"
          cron: "32 11  * * *"
          action:
            invoke_plugin:
              type: "downloader"
              args:
                files:
                  - url: "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/gfw.txt"
                    path: "gfw.txt"
                  - url: "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/reject-list.txt"
                    path: "reject-list.txt"
                  - url: "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/direct-list.txt"
                    path: "direct-list.txt"
                  - url: "https://raw.githubusercontent.com/Loyalsoldier/geoip/release/text/cn.txt"
                    path: "china-ip-list.txt"
                  - url: "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/proxy-list.txt"
                    path: "proxy-list.txt"
                  - url: "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/apple-cn.txt"
                    path: "apple-cn.txt"
                  - url: "https://raw.githubusercontent.com/lazywalker/ghosts/refs/heads/master/hosts.mdns"
                    path: "hosts-github.txt"
                timeout_secs: 30
                concurrent: false

  # ========================================================================
  # Cache, Redirect Plugins, and ROS Addrlist Updater
  # ========================================================================

  # cache plugin to speed up lookups
  - tag: cache
    type: cache
    args:
      size: 1024
      negative_cache: true

  # redirect plugin for specific domains
  - tag: redirect
    type: redirect
    args:
      rules:
        - www.cnbeta.com www.cnbeta.com.cdn.cloudflare.net

  # ROS Addrlist updater for gfwlist IPs
  - tag: add_gfwlist
    type: ros_addrlist
    args:
      addrlist: "mosdns-gfwlist"
      server: "http://192.168.88.1:80"
      user: "mosdns"
      passwd: "Mosisgood"
      mask4: 24
      mask6: 32

  # ========================================================================
  # Upstream Servers
  # ========================================================================

  # forward to domestic DNS, concurrent queries
  - tag: upstream_direct
    type: forward
    args:
      concurrent: 2
      upstreams:
        - addr: udp://119.29.29.29 # Tencent Public DNS
        - addr: udp://223.5.5.5 # AliDNS Public DNS

  # forward to proxy DNS, concurrent queries
  - tag: upstream_proxy
    type: forward
    args:
      concurrent: 2
      upstreams:
        - addr: tcp://8.8.8.8 # Google Public DNS
        - addr: tcp://1.1.1.1 # Cloudflare DNS

  # blackhole upstream for rejected domains
  - tag: upstream_reject
    type: blackhole

  # ========================================================================
  # Sub sequence and Fallback Logic
  # ========================================================================

  # direct sub-sequence, accpt domestic IPs, drop others
  - tag: sequence_direct
    type: sequence
    args:
      - exec: $upstream_direct
      - matches: resp_ip $ip_direct_list
        exec: drop_resp
      - exec: accept

  # proxy sub-sequence
  - tag: sequence_proxy
    type: sequence
    args:
      - exec: $upstream_proxy
      - exec: accept

  # sub-sequence for gfwlist,
  # adding IPs to some list(by exec ROS updater) before accepting when not domestic
  - tag: sequence_gfwlist
    type: sequence
    args:
      - exec: ttl 300-3600
      - matches: "!resp_ip $ip_direct_list"
        exec: $add_gfwlist
      - exec: accept

  # fallback sequence
  - tag: fallback
    type: fallback
    args:
      primary: sequence_direct
      secondary: sequence_proxy
      threshold: 500
      always_standby: true

  # ========================================================================
  # Main sequence - the core DNS processing logic
  # ========================================================================

  # main sequence
  - tag: sequence_main
    type: sequence
    args:
      # check hosts files first
      - exec: $hosts_files
      - matches: has_resp
        exec: accept

      # reject PTR and DNSSEC to fix some iOS issues
      - matches: qtype 12 65
        exec: reject 0

      # block ads
      - matches: qname $domain_reject_list
        # demonstration: use inline quick-setup to blackhole
        exec: black_hole 127.0.0.1
        # or use the upstream_reject defined above
        # exec: $upstream_reject

      - exec: prefer_ipv4

      - exec: $redirect

      # skip cache for dynamic domains, others use cache
      - matches: "!qname 00006801.com"
        exec: $cache
      - matches: has_resp
        exec: accept

      # domestic domains
      - matches: qname $domain_direct_list
        exec: $upstream_direct
      - matches: has_resp
        exec: accept

      # foreign domains
      - matches: qname $domain_proxy_list
        exec: $upstream_proxy
      - matches: has_resp
        exec: jump sequence_gfwlist

      # other unknown domains
      - exec: $fallback

  # ========================================================================
  # Server Configurations, listen on multiple protocols and ports
  # ========================================================================

  # UDP server (built-in)
  - tag: udp_server
    type: udp_server
    args:
      entry: sequence_main
      listen: :5354

  # TCP server (built-in)
  - tag: tcp_server
    type: tcp_server
    args:
      entry: sequence_main
      listen: :5354

  # DNS over HTTPS (DoH) server (requires tls and doh features)
  - tag: doh_server
    type: doh_server
    args:
      entry: sequence_main
      # use unprivileged port for examples; change to :443 for production
      listen: :8443
      # Paths to certificate and private key PEM files (relative to this config dir)
      cert_file: certs/cert.pem
      key_file: certs/key.pem

  # DNS over TLS (DoT) server (requires tls and dot features)
  - tag: dot_server
    type: dot_server
    args:
      entry: sequence_main
      # standard DoT port is 853; use 8853 in examples if you need non-root port
      listen: :8853
      # Paths relative to this config directory
      cert_file: certs/cert.pem
      key_file: certs/key.pem

  # DNS over QUIC (DoQ) server (requires tls and doq features)
  - tag: doq_server
    type: doq_server
    args:
      entry: sequence_main
      # standard DoQ port is 784; use 8784 in examples if you need non-root port
      listen: :8784
      # Paths relative to this config directory
      cert_file: certs/cert.pem
      key_file: certs/key.pem

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

log:
  # * trace | debug | info |warn | error
  level: debug

  # * text (by default) | json
  # format: text

  # * optional; if not set, logs to stdout
  # file: test.log

  # * daily | hourly | never (by default)
  # rotate: daily

  # * optional; overrides parent dir of `file`
  # rotate_dir: /var/log/lazydns
# ============================================================================
# END OF CONFIGURATION
# ============================================================================

# ============================================================================
# FILE UPDATER SCHEDULE DETAILS
# ============================================================================
#
# The scheduler will trigger at:
#   - Time: 02:05 UTC every day
#   - Action: Download all files in the files list
#   - Download Mode: Sequential (one at a time) to avoid bandwidth spikes
#   - Timeout: 30 seconds per file
#   - Retry: Built-in retry on network errors
#
# After files are downloaded:
#   1. Files are written to temporary locations
#   2. Atomically renamed to final paths (no partial files)
#   3. File watches detect the change automatically
#   4. DomainSet/IPSet/Hosts reload the new content
#   5. DNS queries immediately use updated rules
#
# Performance Notes:
#   - With 6 files and sequential mode: ~6-12 seconds typical (varies by file size)
#   - Concurrent mode: ~2-3 seconds but higher bandwidth usage
#   - File reloads happen in background, no DNS query interruption
#   - Failed downloads logged but don't prevent DNS operation
#
# For production deployments:
#   - Monitor logs for download failures: grep "download failed" logs/lazydns.log
#   - Verify file sizes after update: ls -la *.txt
#   - Consider downloading during off-peak hours (e.g., 03:05 UTC instead of 02:05)
#   - Set timeout_secs based on file sizes and network speed
